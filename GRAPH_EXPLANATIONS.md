# Graph Explanations for Presentation

This document contains the **Speaker Scripts** for your 7 key results charts. Use these to explain the "Results" and "Solution" sections of your presentation.

---

## üèóÔ∏è Part 1: The Problem (Results)

### 1. The Reality Gap (Slide 17)
**Visual:** `slide_17_reality_gap.png`
**The One-Liner:** *"Standard theory is dangerous because it ignores the tail."*

**üó£Ô∏è Speaker Script:**
"This chart shows why we built TraceBreaker.
*   **The Blue Line** is the standard M/M/N model. It predicts that latency stays low until the system is 90% full. It looks safe.
*   **The Red Line** is reality‚Äîour simulation using Pareto traffic. Notice how it spikes much earlier, at 70% load.
*   **The Shaded Zone** is the 'Reality Gap'. If you build your system based on the Blue Line, you will crash in the Red Zone. This is the unpredicted risk of heavy-tailed workloads."

### 2. The 36-Second Crash (Slide 19)
**Visual:** `slide_19_crash.png`
**The One-Liner:** *"Heterogeneity isn't just a nuisance; it's a catastrophe."*

**üó£Ô∏è Speaker Script:**
"We often assume that adding 'slow' servers just makes the average slightly slower. This chart proves otherwise.
*   **Left Bar**: Our homogeneous cluster runs at a healthy **60ms**.
*   **Right Bar**: When we introduce just 40% legacy nodes, the system doesn't just slow down‚Äîit collapses. Latency hits **36,000ms**.
*   **Why?** The load balancer keeps sending requests to the slow nodes, which can't keep up. They become 'black holes' for traffic, causing a death spiral."

### 3. The Safety Tax (Slide 20)
**Visual:** `slide_20_safety_tax.png`
**The One-Liner:** *"Consistency is a product feature, and it has a price tag."*

**üó£Ô∏è Speaker Script:**
"We often talk about 'Strong Consistency' as an abstract concept. Here, we measured its physical cost.
*   **Phase 1 (Green)**: With Eventual Consistency, we enjoy a fast 60ms baseline.
*   **Phase 2 (Blue)**: The moment we enable 2PC (Two-Phase Commit), latency jumps to 210ms.
*   **The Gap**: That **150ms jump** isn't inefficient code. It is the 'Safety Tax'‚Äîthe unavoidable network round-trip time required to write to the log and get a consensus. You pay this tax in milliseconds to buy data integrity."

### 4. The Fairness Tax (Slide 21)
**Visual:** `slide_21_fairness_tax.png`
**The One-Liner:** *"Strict fairness creates a traffic jam."*

**üó£Ô∏è Speaker Script:**
"This chart compares 'Unordered' processing vs. 'Strict FIFO'.
*   **The Green Line** shows unordered processing scaling linearly.
*   **The Orange Line** shows Strict FIFO growing exponentially.
*   **The Gap** is 'Head-of-Line Blocking'. In a distributed system, if one message is slow, *everyone behind it waits*. We are paying a massive performance penalty just to keep things in order."

---

## üõ†Ô∏è Part 2: The Solution (Engineering)

### 5. The Work Stealing Fix (Slide 22)
**Visual:** `slide_22_work_stealing.png`
**The One-Liner:** *"We fixed the crash without buying a single new server."*

**üó£Ô∏è Speaker Script:**
"Remember the 36-second crash? Here is the fix.
*   **Left Bar**: The naive routing strategy that failed (36,000ms).
*   **Right Bar**: With **Work Stealing** enabled, latency drops to **250ms**.
*   **How?** We didn't add hardware. We simply allowed the idle 'Fast Servers' to reach over and steal jobs from the 'Slow Queues'. This dynamic load balancing completely neutralized the heterogeneity penalty."

### 6. The Load Shedding Safety Valve (Slide 23)
**Visual:** `slide_23_load_shedding.png`
**The One-Liner:** *"It is better to reject 1% of users than to crash for 100%."*

**üó£Ô∏è Speaker Script:**
"When a Pareto burst hits, you have two choices.
*   **The Grey Line** shows what happens if you try to handle everything: the queue grows to infinity, and the server crashes.
*   **The Blue Line** is TraceBreaker. We set a hard limit (K=50).
*   **The Result**: Latency rises but hits a 'Rejection Threshold' and stays stable. We sacrifice a few requests to save the system from total collapse."

### 7. QoS Divergence (Slide 24)
**Visual:** `slide_24_qos_divergence.png`
**The One-Liner:** *"Priority is a zero-sum game."*

**üó£Ô∏è Speaker Script:**
"Finally, we implemented Priority Queues to help VIP users.
*   **The Green Line**: VIP latency drops to near zero. They are happy.
*   **The Red Line**: But look at the Standard users. Their latency *increases* significantly compared to the baseline.
*   **The Insight**: We didn't make the server faster. We just reshuffled the misery. We saved the VIPs by starving the standard users. This proves that QoS is purely a policy decision, not a performance optimization."
